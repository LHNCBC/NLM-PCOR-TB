import os
os.environ["KMP_DUPLICATE_LIB_OK"]="TRUE"
from nnunet.training.model_restore import recursive_find_python_class
import numpy as np
import argparse
from nnunet.preprocessing.preprocessing import (
    get_lowres_axis,
    get_do_separate_z,
    resample_data_or_seg
)
import pathlib
import SimpleITK as sitk
from collections import OrderedDict
from scipy.ndimage import binary_fill_holes
import pickle
import nnunet


"""
This script is used to predict the binary lung masks on the test CTs using the
a single pretrained lung segmentation model.It also saves the predicted binary
lung masks in the given output folder.
"""

def load_model(model_path):
    """
    This function loads the model from the model path
    ''
    Args:
        model_path(str): Load the model from the model path
    Returns:
          model(nnUNetTrainerV2): Trainer class .
    """
    pkl_file = str(
        pathlib.Path(model_path).parent / (pathlib.Path(model_path).name + ".pkl")
    )

    plans_file = str(
        pathlib.Path(model_path).parent / "lung_segment_network_plans.pkl")

    with open(pkl_file,'rb') as f:
        info = pickle.load(f)

    name = info['name']
    search_in = str(pathlib.Path(nnunet.__path__[0]) / "training" / "network_training")

    tr = recursive_find_python_class([search_in], name, current_module="nnunet.training.network_training")

    model = tr(plans_file = plans_file, output_folder='.',fold=0,deterministic=True, fp16=True)
    model.process_plans(info['plans'])
    model.dataset_directory = '.'
    model.load_checkpoint(model_path, train=False)

    return model


def resample_pred_label(
    prediction_label,
    properties_dict,
    force_separate_z=None,
    order=1,
    interpolation_order_z=0,
):

    """
    This function resamples the prediction label generated by the model back to
    the original size for a given CT volume. For more
    reference on this function, please refer:
    https://github.com/MIC-DKFZ/nnUNet/blob/c0a999f80aac464f115ed3cff45d22b22d47c8fb/nnunet/inference/predict.py#L131
    ''
    Args:
        prediction_label(np.ndarray): Prediction label from the model.
                                      (May or may not be in the original size of the image)
        properties_dict(dict): Dictionary object contaning the properties of an image.
        interpolation_order_z(int):order of interpolation along z
        order(int): order of the spline interpolation.
        force_separate_z(bool): Can be None, True or False. Forcing separate z will resample the
                                CT volume to resample it by slice by slice.
        interpolation_order_z(int): order of the split interpolation
    Returns:
          seg_old_spacing(np.ndarray): Resampled softmax to original size.
    """

    # first resample, then put result into bbox of cropping
    current_shape = prediction_label.shape
    shape_original_after_cropping = properties_dict.get("size_after_cropping")

    if np.any(
        [
            i != j
            for i, j in zip(
                np.array(current_shape), np.array(shape_original_after_cropping)
            )
        ]
    ):
        if force_separate_z is None:
            if get_do_separate_z(properties_dict.get("original_spacing")):
                do_separate_z = True
                lowres_axis = get_lowres_axis(properties_dict.get("original_spacing"))
            elif get_do_separate_z(properties_dict.get("spacing_after_resampling")):
                do_separate_z = True
                lowres_axis = get_lowres_axis(
                    properties_dict.get("spacing_after_resampling")
                )
            else:
                do_separate_z = False
                lowres_axis = None
        else:
            do_separate_z = force_separate_z
            if do_separate_z:
                lowres_axis = get_lowres_axis(properties_dict.get("original_spacing"))
            else:
                lowres_axis = None

        if lowres_axis is not None and len(lowres_axis) != 1:
            # this happens for spacings like (0.24, 1.25, 1.25) for example. In that case we do not want to resample
            # separately in the out of plane axis
            do_separate_z = False

        seg_old_spacing = resample_data_or_seg(
            prediction_label[None],
            shape_original_after_cropping,
            is_seg=True,
            axis=lowres_axis,
            order=order,
            do_separate_z=do_separate_z,
            order_z=interpolation_order_z,
        )
    else:
        seg_old_spacing = prediction_label

    return seg_old_spacing


def create_nonzero_mask(data):
    """
    Create non zero mask with the same shape as the original image array.
    Args:
        data(np.ndarray): Numpy array containing the original image array.
    Returns:
         nonzero_mask(np.ndarray): Non zero mask
    """
    nonzero_mask = np.zeros(data.shape[1:], dtype=bool)
    for c in range(data.shape[0]):
        this_mask = data[c] != 0
        nonzero_mask = nonzero_mask | this_mask
    nonzero_mask = binary_fill_holes(nonzero_mask)
    return nonzero_mask


def get_bbox_from_mask(mask, outside_value=0):
    """
    Extract bounding box from the mask.
    Args:
        mask(np.ndarray): Numpy array containing the original image array.
        outside_value(int): Background value of the image.
    Returns:
         [[minzidx, maxzidx], [minxidx, maxxidx], [minyidx, maxyidx]](list):
             List of lists containing bounding box coordinates.
    """
    mask_voxel_coords = np.where(mask != outside_value)
    minzidx = int(np.min(mask_voxel_coords[0]))
    maxzidx = int(np.max(mask_voxel_coords[0])) + 1
    minxidx = int(np.min(mask_voxel_coords[1]))
    maxxidx = int(np.max(mask_voxel_coords[1])) + 1
    minyidx = int(np.min(mask_voxel_coords[2]))
    maxyidx = int(np.max(mask_voxel_coords[2])) + 1
    return [[minzidx, maxzidx], [minxidx, maxxidx], [minyidx, maxyidx]]


def crop_to_bbox(image, bbox):
    """
    Crop the CT image using the bounding box.
    Args:
        image(np.ndarray): Numpy array containing the original image array.
        bbox(list): List of bounding box coroners in each direction.
                    ([[minzidx, maxzidx], [minxidx, maxxidx], [minyidx, maxyidx]])
    Returns:
         image[resizer](np.ndarray): Cropped image array containing non zero  values.
    """
    resizer = (
        slice(bbox[0][0], bbox[0][1]),
        slice(bbox[1][0], bbox[1][1]),
        slice(bbox[2][0], bbox[2][1]),
    )
    return image[resizer]


def preprocess_image(training_dataset_properties, img):
    """
    This function preprocesses the given volume using the trained model and
    is done in 3 steps.
    1. Crop the foreground containing nonzero values.
    2. Resample the cropped image to target spacing . This target spacing is stored
        in the dataset proeprty pickle file.
    3. Normalize the resampled image to mean=0 and std=1 before clipping the intensity values
        of the input test image to 0.5 and 99.5 percentile of the training dataset intensities.
        These percentile values are read from the dictionary object with key values
    Args:
        training_dataset_properties(dict): Dictionary containing dataset properties
                                        that the model has trained on.
        img(SimpleITK.Image): Loaded SimpleITK image.
    Returns:
          data(np.ndarray): Final preprocessed array of the CT volume.
          test_image_properties(dict): Dictionary containing the properties of the
                                      test CT volume with keys like "itk_origin",
                                      "itk_spacing","itk_direction" representing
                                      origin, spacing and the direction of the given
                                      CT volume.
          bbox(list):  [[minzidx, maxzidx], [minxidx, maxxidx], [minyidx, maxyidx]](list):
             List of lists containing bounding box coordinates.
    """

    transpose_forward = [0, 1, 2]
    intensity_properties = training_dataset_properties["plans"]["dataset_properties"][
        "intensityproperties"
    ]

    arr = sitk.GetArrayFromImage(img)
    test_image_properties = OrderedDict()

    test_image_properties["original_size_of_raw_data"] = np.array(img.GetSize())[
        [2, 1, 0]
    ]
    test_image_properties["original_spacing"] = np.array(img.GetSpacing())[[2, 1, 0]]

    test_image_properties["itk_origin"] = img.GetOrigin()
    test_image_properties["itk_spacing"] = img.GetSpacing()
    test_image_properties["itk_direction"] = img.GetDirection()

    data = np.reshape(arr.astype(np.float32), (1,) + arr.shape)

    # Cropping
    nonzero_mask = create_nonzero_mask(data)
    bbox = get_bbox_from_mask(nonzero_mask, 0)

    cropped_data = []
    for c in range(data.shape[0]):
        cropped = crop_to_bbox(data[c], bbox)
        cropped_data.append(cropped[None])
    data = np.vstack(cropped_data)
    nonzero_mask = crop_to_bbox(nonzero_mask, bbox)[None]

    test_image_properties["crop_bbox"] = bbox
    test_image_properties["size_after_cropping"] = data[0].shape

    # Resampling
    data = data.transpose((0, *[i + 1 for i in transpose_forward]))

    target_spacing = training_dataset_properties["plans"]["plans_per_stage"][0][
        "current_spacing"
    ]

    original_spacing_transposed = np.array(test_image_properties["original_spacing"])[
        transpose_forward
    ]

    data[np.isnan(data)] = 0
    target_spacing[0] = original_spacing_transposed[0]

    shape = np.array(data[0].shape)
    new_shape = np.round(
        (
            (
                np.array(test_image_properties["original_spacing"])
                / np.array(target_spacing)
            ).astype(float)
            * shape
        )
    ).astype(int)

    RESAMPLING_SEPARATE_Z_ANISO_THRESHOLD = 3
    if get_do_separate_z(
        test_image_properties["original_spacing"], RESAMPLING_SEPARATE_Z_ANISO_THRESHOLD
    ):
        do_separate_z = True
        axis = get_lowres_axis(test_image_properties["original_spacing"])
    elif get_do_separate_z(target_spacing, RESAMPLING_SEPARATE_Z_ANISO_THRESHOLD):
        do_separate_z = True
        axis = get_lowres_axis(target_spacing)
    else:
        do_separate_z = False
        axis = None

    if axis is not None:
        if len(axis) == 3:
            do_separate_z = False
        elif len(axis) == 2:
            # this happens for spacings like (0.24, 1.25, 1.25) for example. In that case we do not want to resample
            # separately in the out of plane axis
            do_separate_z = False
        else:
            pass
    order_data = 3
    order_z_data = 0
    data_reshaped = resample_data_or_seg(
        data, new_shape, False, axis, order_data, do_separate_z, order_z=order_z_data
    )

    test_image_properties["size_after_resampling"] = data[0].shape
    test_image_properties["spacing_after_resampling"] = target_spacing

    # Normalize intensities
    # clip to lower bound and upper bound from train data foreground and use
    # foreground mn and sd from training data
    mean_intensity = intensity_properties[0]["mean"]
    std_intensity = intensity_properties[0]["sd"]
    lower_bound = intensity_properties[0]["percentile_00_5"]
    upper_bound = intensity_properties[0]["percentile_99_5"]
    data = np.clip(data_reshaped, lower_bound, upper_bound)
    data = (data - mean_intensity) / std_intensity

    return data, test_image_properties, bbox

def crop_from_simpleitk(sitk_img):
    label_shape_filter = sitk.LabelShapeStatisticsImageFilter()
    new_shape = list(sitk_img.GetSize())
    new_shape.reverse()
    sample = sitk.GetImageFromArray(np.zeros(new_shape,dtype=np.int64))
    sample.CopyInformation(sitk_img)
    label_shape_filter.Execute(sitk.BinaryFillhole(sample | sitk.Cast((sitk_img != 0),sitk.sitkInt64)))
    bounding_box = label_shape_filter.GetBoundingBox(1)
    # The bounding box's first "dim" entries are the starting index and last "dim" entries the size
    return sitk.RegionOfInterest(
        sitk_img,
        bounding_box[int(len(bounding_box) / 2) :],
        bounding_box[0 : int(len(bounding_box) / 2)],
    )


def predict_segmentation(
    model, d, dct,bbox, mixed_precision=True, all_in_gpu=None, step_size=0.5, do_tta=False
):

    """
    This function predicts the lung segmentation in CTs by a single model .
    Args:
        model(nnUNetTrainerV2): Loaded nnUNet model.
        d(np.ndarray): preprocessed numpy array
        dct(dict): properties of the pre processed array of the image.
        bbox(list):  [[minzidx, maxzidx], [minxidx, maxxidx], [minyidx, maxyidx]](list):
           List of lists containing bounding box coordinates.
        mixed_precision(bool):  if None then we take no action. If True/False we
                                overwrite what the model has in its init
        step_size(float): Not proper documentation is available in original source code
        do_tta(bool): False, can be set to True for improved segmentation quality.
                      When the flag is True, the computations take 8 times longer.
        all_in_gpu(list): List of GPU IDs so that distributed data parallel computing can be
                          used. But is not recommended by nnUNet documentation:
                          https://github.com/MIC-DKFZ/nnUNet#multi-gpu-training
    Returns:
        pred_label_original_size(np.ndarray):Prediction label generated by a given model.
    """
    pred_label_after_resampling_after_cropping = model.predict_preprocessed_data_return_seg_and_softmax(
        d,
        do_mirroring=do_tta,
        mirror_axes=model.data_aug_params["mirror_axes"],
        use_sliding_window=True,
        step_size=step_size,
        use_gaussian=True,
        all_in_gpu=all_in_gpu,
        mixed_precision=mixed_precision,
    )[0]
    #pred_label_after_resampling_after_cropping = softmax.argmax(0)

    transpose_forward = model.plans.get("transpose_forward")
    if transpose_forward is not None:
        transpose_backward = model.plans.get("transpose_backward")
        pred_label_after_resampling_after_cropping = pred_label_after_resampling_after_cropping.transpose(
            [0] + [i + 1 for i in transpose_backward[:-1]]
        )

    #  Resize the prediction mask to the original size.
    if not np.all(
        pred_label_after_resampling_after_cropping.shape == dct.get("original_size_of_raw_data")
    ):

        pred_label_after_resampling_after_cropping_img = sitk.GetImageFromArray(pred_label_after_resampling_after_cropping.astype(np.uint8))
        pred_label_after_resampling_after_cropping_img.SetSpacing(dct.get("spacing_after_resampling")[::-1].tolist())
        pred_label_after_resampling_after_cropping_img.SetOrigin(dct["itk_origin"])
        pred_label_after_resampling_after_cropping_img.SetDirection(dct["itk_direction"])
        new_spacing = [
            sz * spc / nsz
            for nsz, sz, spc in zip(list(dct.get("size_after_cropping")[::-1]),
                                    pred_label_after_resampling_after_cropping_img.GetSize(),
                                    list(dct.get("spacing_after_resampling")[::-1]))
        ]
        pred_label_before_resampling_after_cropping_img = sitk.Resample(pred_label_after_resampling_after_cropping_img,
                                      list(dct.get("size_after_cropping")[::-1]),
                                    sitk.Transform(),
                                    sitk.sitkNearestNeighbor,
                                    pred_label_after_resampling_after_cropping_img.GetOrigin(),
                                    new_spacing,
                                    pred_label_after_resampling_after_cropping_img.GetDirection(),
                                    0, sitk.sitkInt32)
        pred_label_before_resampling_after_cropping = sitk.GetArrayFromImage(pred_label_before_resampling_after_cropping_img)
        pred_label_before_resampling_before_cropping = np.zeros(dct.get("original_size_of_raw_data"),dtype=np.uint8)
        for c in range(3):
            bbox[c][1] = np.min((bbox[c][0] + pred_label_before_resampling_after_cropping.shape[c],
                                  pred_label_before_resampling_before_cropping.shape[c]))
        pred_label_before_resampling_before_cropping[bbox[0][0]:bbox[0][1],
        bbox[1][0]:bbox[1][1],
        bbox[2][0]:bbox[2][1]] = pred_label_before_resampling_after_cropping

    else:
        pred_label_before_resampling_before_cropping = pred_label_after_resampling_after_cropping.astype(np.uint8)

    pred_label_img = sitk.GetImageFromArray(pred_label_before_resampling_before_cropping)
    pred_label_img.SetOrigin(dct["itk_origin"])
    pred_label_img.SetDirection(dct["itk_direction"])
    pred_label_img.SetSpacing(dct["itk_spacing"])
    return pred_label_img


def get_prediction_label(model, training_dataset_properties, img_path):

    """
    This function predicts the lung segmentation using the nnUNet model and the
    image path.
    Args:
        model(nnUNetTrainerV2): Loaded nnUNet model class.
        img_path(dict): CT path.
    Returns:
        pred_label_img(SimpleITK.Image): Predicted binary mask  by the model.
    """

    preprocessed_arr, dct, bbox = preprocess_image(training_dataset_properties, img_path)

    pred_label = predict_segmentation(model, preprocessed_arr, dct,bbox)

    return pred_label


def _get_dataset_properties_and_model(model_path):
    """
    Extract dataset properties and the model. The dataset properties are nothing but
    the charcateristics of the data that the nnUNet model has been trained on.
    Args:
        model_path(np.ndarray): Numpy array containing the original image array.
    Returns:
          model(nnUNetTrainerV2): Loaded nnUNet segmentation model.
          train_dataset_properties(dict): Dictionary containing the properties of the
                                      training dataset that the model has been trained on.
    """
    model = load_model(model_path)
    pkl_file = str(
        pathlib.Path(model_path).parent / (pathlib.Path(model_path).name + ".pkl")
    )
    with open(pkl_file, "rb") as f:
        train_dataset_properties = pickle.load(f)
    return model, train_dataset_properties


def postprocess_label(pred_label, threshold=549000):
    """
    Post process the predicted binary mask by filtering the lung volumes
    of the mask and dilating the missing objects in the lung volume by 1 mm.
    The filter to the lung volume is determined based on the lower limit of
    the left lung volume and right lung volumes , 864 +/− 315 ml and 1035 +/− 280 ml
    respectively.
    (Reference:https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4118261/).
    Without this post processing function, the results on the test set by the
    nnUNet models resulted in 0. whereas when the same post processing function
    is employed on the predicted labels, the dice coefficient is 0.
    Args:
        pred_label(SimpleITK.Image): Predicted binary mask  by the model.
        threshold(integer): Threshold (in mm3) for filtering lung volumes.
    Returns:
       postprocessed_image(SimpleITK.Image): Post processed image after filtering the objects.
    """

    spacing = pred_label.GetSpacing()
    size_of_voxel = spacing[0] * spacing[1] * spacing[2]

    disjointed_segmentation_image = sitk.RelabelComponent(
        sitk.ConnectedComponent(pred_label),
        minimumObjectSize=int(threshold / size_of_voxel),
    )

    postprocessed_image = disjointed_segmentation_image > 0

    return postprocessed_image


def main():
    parser = argparse.ArgumentParser(
        "Prediction of segmentations located in the folder."
    )
    parser.add_argument(
        "ct_path",
        type=pathlib.Path,
        help="Input path for the CT volume",
    )
    parser.add_argument(
        "model_path",
        type=str,
        help="Path of trained segmentation model on CTs ",
    )
    parser.add_argument(
        "output_pred_filename",
        type=str,
        help="Output image directory to save predictions.",
    )
    parser.add_argument(
        "--post_process",
        action="store_true",
        help="If post processing is requested,True, the prediction label generated \
        by the modelwill under go,one more additional step of post processing.\
        If False, the prediction label will not go udnergo that step",
    )
    args = parser.parse_args()

    ct_image = sitk.ReadImage(str(pathlib.Path(args.ct_path)))

    (
        lung_segmentation_model,
        lung_training_dataset_properties,
    ) = _get_dataset_properties_and_model(args.model_path)
    pred_label = get_prediction_label(
        lung_segmentation_model, lung_training_dataset_properties, ct_image
    )
    if args.post_process:
        pred_label = postprocess_label(pred_label)

    sitk.WriteImage(pred_label, args.output_pred_filename)


if __name__ == "__main__":
    main()